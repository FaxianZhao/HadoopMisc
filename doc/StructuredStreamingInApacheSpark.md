https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html

#使用Apache Spark进行结构化流处理
##关于流处理的一种新型高级API

为了构建连续型应用，Apache 2.0增加了第一版Structured Streaming。主旨在于更轻松的构建一种具有一致性和容错性的流式应用，
它整合存储，服务系统和批量任务。在这篇文章中，我们解释为什么它很难在现有的分布式流处理引擎实施，还会介绍Structured Streaming。  

##为什么流处理很难
乍一看，构建一个分布式流引擎就像提交一系列服务然后在它们之间推送数据一样简单。不幸的是，分布式流处理在高并发的状态下并不像计算一批任务一样简单。  
首先，考虑一个简单的场景：我们从手机APP接收（phone_id, time, action）事件，然后计算每小时每种类型的事件发生多少次，然后把这些数据存储在mysql中。
如果我们有一张包含所有输入事件的表，然后把这个任务作为批任务进行执行，我们可以用以下的SQL语句进行处理：  
```
SELECT action, WINDOW(time, "1 hour"), COUNT(*)
FROM events
GROUP BY action, WINDOW(time, "1 hour")
```
在分布式流处理引擎中，我们可能会建立几个节点然后以"map-reduce"的形式处理这些数据，就像下面展示的一样。  
每个节点在第一层读取一个分区中的输入数据(就是一组手机的数据流),然后哈希这些事件（根据action, hour）发送给一个reducer节点，这个节点会处理这个组的总数，并且周期性的更新Mysql。  
![整体物理架构](https://databricks.com/wp-content/uploads/2016/07/image00-2.png)
不幸的是，这种架构会引入一些问题：
1. 一致性：这种分布式架构会使数据的业务逻辑在不同区域的系统中去处理，而导致结果无意义。举个例子，假设当用户打开APP时，我们发送一个“open”事件，用户关闭APP时，我们发送一个“close”事件。  
如果reducer节点处理“open”事件慢于“close”事件，我们可能会在mysql中看到“close”的总数比“open”的多，但这不合逻辑。上图就显示了这种问题。  
2. 容错性：如果有一个mapper或reducer失败了会怎么样？一个Reducer不应该把计算结果写如mysql两次，但应该知道如何从mapper中获取旧数据。流式引擎为了提供强大的语义带来了很多麻烦，至少在这种引擎中。  
在很多引擎中，对于其他外部存储的一致性，往往交给用户自己。  
3. 过时数据：在实际应用中，不同源头的数据不是按照它发生的顺序发送到引擎的。比如，当一个手机不在服务区时，它可能会在几个小时后才上传数据。如果reducer的逻辑只是假设数据会以顺序接收，那它就失效了。它需要对过时数据有自己的处理办法。  

在很多现有的流式系统中，多少会把这些问题留给用户去处理。

